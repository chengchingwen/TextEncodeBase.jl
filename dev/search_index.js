var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = TextEncodeBase","category":"page"},{"location":"#TextEncodeBase","page":"Home","title":"TextEncodeBase","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for TextEncodeBase.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [TextEncodeBase]","category":"page"},{"location":"#TextEncodeBase.AbstractTokenization","page":"Home","title":"TextEncodeBase.AbstractTokenization","text":"abstract type for tokenization.\n\nThe tokenization procedure is separate into multiple  TokenStages and recursive calls of splitting and  tokenize. splitting break string into substrings,  and tokenize is responsible for marking each substring  with a TokenStages and do the tokenization.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.AbstractTokenizer","page":"Home","title":"TextEncodeBase.AbstractTokenizer","text":"abstract type for tokenizers.\n\nEach tokenizer is link with a tokenization (by  defining tokenization(::Tokenizer) = Tokenization()).  The overall framework dispatch on both tokenizer and  tokenization, but most of the time we only add methods  for tokenization. This allow further composability and  can interfere the tokenization process with given  tokenizer.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.NaiveIndexedTokenizer","page":"Home","title":"TextEncodeBase.NaiveIndexedTokenizer","text":"default behavior but counting the index\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.NaiveTokenizer","page":"Home","title":"TextEncodeBase.NaiveTokenizer","text":"tokenizer that run the default behavior\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.TokenStages","page":"Home","title":"TextEncodeBase.TokenStages","text":"abstract type for type that wrap input into specific stage for control tokenization.\n\nThere are six builtin stages in TextEncodeBase (all abstract XStage <: TokenStages):\n\nDocument <: DocumentStage: the input string is a full document,\n\nand thus need to be splitted into multiple sentence.\n\nSentence <: SentenceStage: the input string is a full string,\n\nand thus need to be splitted into multiple part (SubSentence/Word/Token).\n\nSubSentence <: SubSentenceStage: special wrapper for case where the tokenizer\n\ndoes not directly break sentence all into words/tokens and these pieces contain  multiple words/tokens, but you need the information that they are not full sentence.\n\nWord <: WordStage: the input string is a single word.\nSubWord <: SubWordStage: similar to SubSentence, but for word.\nToken <: TokenStage: the final piece of the tokenization process.\n\nGenerally, it's used to specify the end of this piece and should  never be splitted.\n\nEach wrapper have two field: x for the input, meta for extra information (nothing if not provided).\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.splitting","page":"Home","title":"TextEncodeBase.splitting","text":"splitting(t::AbstractTokenization, x::TokenStages)\n\nSplit x given its tokenization stage. For example,  the default behavior of a document stage is splitting into  sentences (with WordTokenizers.split_sentences).\n\nOverload this method for custom tokenization.\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.splitting-Tuple{TextEncodeBase.AbstractTokenization, TextEncodeBase.TokenStages, Any}","page":"Home","title":"TextEncodeBase.splitting","text":"splitting(t::AbstractTokenization, s::TokenStages, x)\n\nInterface for providing callback for splitting. x is the result of splitting(t, s).\n\nOverload this method for custom splitting callback.\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.tokenize","page":"Home","title":"TextEncodeBase.tokenize","text":"tokenize(t::AbstractTokenization, s::TokenStages, x)\n\nMark the tokenization stage of x, which is part of the splitting result of s.  For example, if we are doing simple whitespace tokenization and at the sentence stage,  then x is just single word of s and thus return Word(x) (or Token(x)).  Skip if x is already a TokenStages.\n\nOverload this method to control the tokenization process.\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.tokenize-Tuple{TextEncodeBase.AbstractTokenizer, TextEncodeBase.AbstractTokenization, TextEncodeBase.TokenStages}","page":"Home","title":"TextEncodeBase.tokenize","text":"tokenize(tkr::AbstractTokenizer, t::AbstractTokenization, x::TokenStages)\n\nTokenize x according to tkr and t\n\nOverload this method for custom tokenizer, tokenization and stages.  Notice that there is no method for tokenize(t, x), so you always  also need to dispatch to AbstractTokenizer.\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.tokenize_procedure-Tuple{Any, Any, Any}","page":"Home","title":"TextEncodeBase.tokenize_procedure","text":"tokenization_procedure(tokenizer, tokenizaton, stage)\n\nThe procedure of tokenization (splitting + tokenize).  This is use to restore full behavior for stage that default  unsplittable. Generally don't overload this function.\n\n\n\n\n\n","category":"method"}]
}
