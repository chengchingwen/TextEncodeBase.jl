var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = TextEncodeBase","category":"page"},{"location":"#TextEncodeBase","page":"Home","title":"TextEncodeBase","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for TextEncodeBase.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [TextEncodeBase]","category":"page"},{"location":"#TextEncodeBase.AbstractTokenization","page":"Home","title":"TextEncodeBase.AbstractTokenization","text":"abstract type for tokenization.\n\nThe tokenization procedure is separate into multiple  TokenStages and recursive calls of splitting, wrap,  and tokenize. splitting break string into substrings,  wrap mark the substrings with new TokenStages, and  tokenize is responsible for the tokenization.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.AbstractTokenizer","page":"Home","title":"TextEncodeBase.AbstractTokenizer","text":"abstract type for tokenizers.\n\nEach tokenizer is link with a tokenization (by  defining tokenization(::Tokenizer) = Tokenization()).  The overall framework dispatch on both tokenizer and  tokenization, but most of the time we only add methods  for tokenization. This allow further composability and  can interfere the tokenization process with given  tokenizer.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.FlatTokenizer","page":"Home","title":"TextEncodeBase.FlatTokenizer","text":"tokenizer that return flat array instead of nested array of tokens\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.NestedTokenizer","page":"Home","title":"TextEncodeBase.NestedTokenizer","text":"tokenizer that return nested array instead of flat array of tokens\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.Splittability","page":"Home","title":"TextEncodeBase.Splittability","text":"splittability trait\n\nThe splittability trait decide whether the given combination (tokenizer x tokenization x stage) is  splittable or not (Splittable or UnSplittable). For example, DefaultTokenization and SentenceStage  is splittable (i.e. splittability(::DefaultTokenization, ::SentenceStage) = Splittable()). The splittability  change the behavior of tokenize: if it's splittable, tokenize will try to call splitting on the input,  wrap each splitting result and recurse. Otherwise, it will directly call wrap and then recurse into tokenize.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.TokenStages","page":"Home","title":"TextEncodeBase.TokenStages","text":"abstract type for type that wrap input into specific stage for control tokenization.\n\nThere are six builtin stages in TextEncodeBase (all abstract XStage <: TokenStages):\n\n1. Document <: DocumentStage: the input string is a full document,\n and thus need to be splitted into multiple sentence.\n2. Sentence <: SentenceStage: the input string is a full string,\n and thus need to be splitted into multiple part (SubSentence/Word/Token).\n3. SubSentence <: SubSentenceStage: special wrapper for case where the tokenizer\n does not directly break sentence all into words/tokens and these pieces contain\n multiple words/tokens, but you need the information that they are not full sentence.\n4. Word <: WordStage: the input string is a single word.\n5. SubWord <: SubWordStage: similar to SubSentence, but for word.\n6. Token <: TokenStage: the final piece of the tokenization process.\n Generally, it's used to specify the end of this piece and should\n never be splitted.\n\nEach wrapper have two field: x for the input, meta for extra information (nothing if not provided).\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.Vocab","page":"Home","title":"TextEncodeBase.Vocab","text":"Vocab(data::Vector{<:AbstractString}, unk::AbstractString=\"[UNK]\")\n\nConstructor for Vocab. data is the list of vocabulary word, can be nonunique.  The actual list will be the unique version of data (i.e. vocab.list = unique(data)).  unk is the indicator word for all unknown words. unk can be either in or not in data,  depends on the use case.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.lookup","page":"Home","title":"TextEncodeBase.lookup","text":"lookup(v::Vocab, x)\n\nLookup x in v. lookup words depends on the type of x. If x is an integer,  return the x-th word on the vocabulary list (i.e. v.list[x]) and return the unknown word  if x is out-of-bound (v.unk). If x is a string, return the indice of x in the vocabulary  list (i.e findfirst(==(x), v.list) and return the unknown indice if x not found in the list.  If the unknown word v.unk is in the list, the unknown indice is its indice, otherwise 0.\n\nExample\n\njulia> vocab = Vocab([\"a\", \"b\", \"c\", \"a\", \"b\", \"c\"])\nVocab{String, StaticArrays.SizedVector{3, String, Vector{String}}}(size = 3, unk = [UNK], unki = 0)\n\njulia> vocab_unk = Vocab([\"a\", \"b\", \"xxx\"], \"xxx\")\nVocab{String, StaticArrays.SizedVector{3, String, Vector{String}}}(size = 3, unk = xxx, unki = 3)\n\njulia> lookup(vocab, \"b\")\n2\n\njulia> lookup(vocab, \"d\")\n0\n\njulia> lookup(vocab_unk, \"d\")\n3\n\njulia> lookup(vocab, 1)\n\"a\"\n\njulia> lookup(vocab, 10000)\n\"[UNK]\"\n\njulia> lookup(vocab_unk, 10000)\n\"xxx\"\n\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.lookup-Tuple{Type{OneHot}, Vocab, Any}","page":"Home","title":"TextEncodeBase.lookup","text":"lookup(OneHot, v::Vocab, i)\n\nlookup i and convert into one-hot representation.\n\nExample\n\njulia> lookup(OneHot, vocab, \"a\")\n3-element OneHot{3}:\n 1\n 0\n 0\n\njulia> lookup(OneHot, vocab, [\"a\" \"b\"; \"c\" \"d\"])\n3x2x2 OneHotArray{3, 3, Matrix{OneHot{0x00000003}}}:\n[:, :, 1] =\n 1  0\n 0  0\n 0  1\n\n[:, :, 2] =\n 0  0\n 1  0\n 0  0\n\njulia> lookup(OneHot, vocab, 3)\nERROR: DomainError with c:\ncannot convert `lookup(::Vocab, 3)` = \"c\" into one-hot representation.\nStacktrace:\n[...]\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.lookup-Tuple{Vocab, AbstractArray}","page":"Home","title":"TextEncodeBase.lookup","text":"lookup(v::Vocab, is::AbstractArray)\n\nrecursively lookup value from is\n\nExample\n\njulia> lookup(vocab, [\"b\", \"c\", \"a\", \"A\", \"[UNK]\"])\n5-element Vector{Int64}:\n 2\n 3\n 1\n 0\n 0\n\njulia> lookup(vocab, [1, \"a\", 0, \"A\", \"[UNK]\"])\n5-element Vector{Any}:\n  \"a\"\n 1\n  \"[UNK]\"\n 0\n 0\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.lookup-Tuple{Vocab, OneHotArray}","page":"Home","title":"TextEncodeBase.lookup","text":"lookup(v::Vocab, i::OneHotArray)\n\nconvert the one-hot representation back into words.\n\nExample\n\njulia> lookup(OneHot, vocab, [\"a\" \"b\"; \"c\" \"d\"])\n3x2x2 OneHotArray{3, 3, Matrix{OneHot{0x00000003}}}:\n[:, :, 1] =\n 1  0\n 0  0\n 0  1\n\n[:, :, 2] =\n 0  0\n 1  0\n 0  0\n\njulia> lookup(vocab, ans)\n2×2 Matrix{String}:\n \"a\"  \"b\"\n \"c\"  \"[UNK]\"\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.nested2batch-Tuple{Any}","page":"Home","title":"TextEncodeBase.nested2batch","text":"nested2batch(x)\n\nconvert nested array into single array\n\nExample\n\njulia> TextEncodeBase.nested2batch([[[1 2],[3 4]]])\n1×2×2×1 Array{Int64, 4}:\n[:, :, 1, 1] =\n 1  2\n\n[:, :, 2, 1] =\n 3  4\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.preprocess-Tuple{AbstractTokenizer, TextEncodeBase.TokenStages}","page":"Home","title":"TextEncodeBase.preprocess","text":"preprocess(tkr::AbstractTokenizer, x)\n\nPreprocess the input x. This is only called during tkr(x).\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.splittability","page":"Home","title":"TextEncodeBase.splittability","text":"splittability(args...)\n\nReturn the splittability (Splittable/UnSplittable) of given argument combination.  Overload to make a TokenStages splittable.\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.splittable-Tuple","page":"Home","title":"TextEncodeBase.splittable","text":"splittable(args...)\n\nReturn true if the splittability of given argument combination is Splittable().\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.splitting","page":"Home","title":"TextEncodeBase.splitting","text":"splitting(t::AbstractTokenization, x::TokenStages)\n\nSplit x given its tokenization stage. For example,  the default behavior of a document stage is splitting into  sentences (with WordTokenizers.split_sentences).\n\nOverload this method for custom tokenization.\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.tokenization-Tuple{AbstractTokenizer}","page":"Home","title":"TextEncodeBase.tokenization","text":"tokenization(::AbstractTokenizer) :: AbstractTokenization\n\nReturn the tokenization type of given tokenizer.\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.tokenize_procedure-Tuple{Any, Any, Any}","page":"Home","title":"TextEncodeBase.tokenize_procedure","text":"tokenization_procedure(tokenizer, tokenizaton, stage)\n\nThe procedure of tokenization (splitting + wrap + tokenize).\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.trunc_and_pad-Tuple{Any, Integer, Any}","page":"Home","title":"TextEncodeBase.trunc_and_pad","text":"trunc_and_pad(x, n, pad)\n\ntruncate x to length n, otherwise add pad at the end of x until length equal n.  x can be either nested or single array (but the element type should not be subtype of abstract array).  if n is nothing, the largest length of the nested array will be used.\n\nExample\n\njulia> TextEncodeBase.trunc_and_pad(1:5, 7, -1)\n7-element Vector{Int64}:\n  1\n  2\n  3\n  4\n  5\n -1\n -1\n\njulia> TextEncodeBase.trunc_and_pad([1:5, 2:7], 7, -1)\n2-element Vector{Vector{Int64}}:\n [1, 2, 3, 4, 5, -1, -1]\n [2, 3, 4, 5, 6, 7, -1]\n\njulia> TextEncodeBase.trunc_and_pad([1:5, [2:7, [1:2]]], nothing, -1)\n2-element Vector{Vector}:\n [1, 2, 3, 4, 5, -1]\n Vector[[2, 3, 4, 5, 6, 7], [[1, 2, -1, -1, -1, -1]]]\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.with_head_tail-Tuple{Any, Any, Any}","page":"Home","title":"TextEncodeBase.with_head_tail","text":"with_head_tail(x, head, tail)\n\nReturn [head; x; tail]. Ignored if head or tail is nothing.\n\nExample\n\njulia> TextEncodeBase.with_head_tail(1:5, -1, -2)\n7-element Vector{Int64}:\n -1\n  1\n  2\n  3\n  4\n  5\n -2\n\njulia> TextEncodeBase.with_head_tail([1:5, 2:3], -1, -2)\n2-element Vector{Vector{Int64}}:\n [-1, 1, 2, 3, 4, 5, -2]\n [-1, 2, 3, -2]\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.wrap","page":"Home","title":"TextEncodeBase.wrap","text":"wrap(t::AbstractTokenization, s::TokenStages, x)\n\nMark the tokenization stage of x, which is part of the splitting result of s.  For example, if we are doing simple whitespace tokenization and at the sentence stage,  then x is just single word of s and thus return Word(x) (or Token(x)).  Skip if x is already a TokenStages. (this method only apply to splittable stages)\n\nOverload this method to control the tokenization process.\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.wrap-Tuple{TextEncodeBase.AbstractTokenization, TextEncodeBase.TokenStages}","page":"Home","title":"TextEncodeBase.wrap","text":"wrap(t::AbstractTokenization, x::TokenStages)\n\nA handler for unsplittable stages (token/word/...).\n\nOverload this method for custom transform.\n\n\n\n\n\n","category":"method"}]
}
