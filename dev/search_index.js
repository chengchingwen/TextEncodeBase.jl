var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = TextEncodeBase","category":"page"},{"location":"#TextEncodeBase","page":"Home","title":"TextEncodeBase","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for TextEncodeBase.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [TextEncodeBase]","category":"page"},{"location":"#TextEncodeBase.AbstractTokenization","page":"Home","title":"TextEncodeBase.AbstractTokenization","text":"abstract type for tokenization.\n\nThe tokenization procedure is separate into multiple  TokenStages and recursive calls of splitting, wrap,  and tokenize. splitting break string into substrings,  wrap mark the substrings with new TokenStages, and  tokenize is responsible for the tokenization.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.AbstractTokenizer","page":"Home","title":"TextEncodeBase.AbstractTokenizer","text":"abstract type for tokenizers.\n\nEach tokenizer is link with a tokenization (by  defining tokenization(::Tokenizer) = Tokenization()).  The overall framework dispatch on both tokenizer and  tokenization, but most of the time we only add methods  for tokenization. This allow further composability and  can interfere the tokenization process with given  tokenizer.\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.NaiveIndexedMatchTokenizer","page":"Home","title":"TextEncodeBase.NaiveIndexedMatchTokenizer","text":"default behavior but counting index and don't split some pattern\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.NaiveIndexedTokenizer","page":"Home","title":"TextEncodeBase.NaiveIndexedTokenizer","text":"default behavior but counting the index\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.NaiveMatchTokenizer","page":"Home","title":"TextEncodeBase.NaiveMatchTokenizer","text":"default behavior but don't split some pattern\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.NaiveTokenizer","page":"Home","title":"TextEncodeBase.NaiveTokenizer","text":"tokenizer that run the default behavior\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.TokenStages","page":"Home","title":"TextEncodeBase.TokenStages","text":"abstract type for type that wrap input into specific stage for control tokenization.\n\nThere are six builtin stages in TextEncodeBase (all abstract XStage <: TokenStages):\n\n1. Document <: DocumentStage: the input string is a full document,\n and thus need to be splitted into multiple sentence.\n2. Sentence <: SentenceStage: the input string is a full string,\n and thus need to be splitted into multiple part (SubSentence/Word/Token).\n3. SubSentence <: SubSentenceStage: special wrapper for case where the tokenizer\n does not directly break sentence all into words/tokens and these pieces contain\n multiple words/tokens, but you need the information that they are not full sentence.\n4. Word <: WordStage: the input string is a single word.\n5. SubWord <: SubWordStage: similar to SubSentence, but for word.\n6. Token <: TokenStage: the final piece of the tokenization process.\n Generally, it's used to specify the end of this piece and should\n never be splitted.\n\nEach wrapper have two field: x for the input, meta for extra information (nothing if not provided).\n\n\n\n\n\n","category":"type"},{"location":"#TextEncodeBase.nested2batch-Tuple{Any}","page":"Home","title":"TextEncodeBase.nested2batch","text":"nested2batch(x)\n\nconvert nested array into single array\n\nExample\n\njulia> TextEncodeBase.nested2batch([[[1 2],[3 4]]])\n1×2×2×1 Array{Int64, 4}:\n[:, :, 1, 1] =\n 1  2\n\n[:, :, 2, 1] =\n 3  4\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.splitting","page":"Home","title":"TextEncodeBase.splitting","text":"splitting(t::AbstractTokenization, x::TokenStages)\n\nSplit x given its tokenization stage. For example,  the default behavior of a document stage is splitting into  sentences (with WordTokenizers.split_sentences).\n\nOverload this method for custom tokenization.\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.splitting-Tuple{TextEncodeBase.AbstractTokenization, TextEncodeBase.TokenStages, Any}","page":"Home","title":"TextEncodeBase.splitting","text":"splitting(t::AbstractTokenization, s::TokenStages, x)\n\nInterface for providing callback for splitting. x is the result of splitting(t, s).\n\nOverload this method for custom splitting callback.\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.tokenization-Tuple{AbstractTokenizer}","page":"Home","title":"TextEncodeBase.tokenization","text":"tokenization(::AbstractTokenizer) :: AbstractTokenization\n\nReturn the tokenization type of given tokenizer.\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.tokenize-Tuple{AbstractTokenizer, TextEncodeBase.AbstractTokenization, TextEncodeBase.TokenStages}","page":"Home","title":"TextEncodeBase.tokenize","text":"tokenize(tkr::AbstractTokenizer, t::AbstractTokenization, x::TokenStages)\n\nTokenize x according to tkr and t.\n\nOverload for custom tokenizer, tokenization and stages. For making a unsplittable  into splittable (or vice versa), you must overload this method.\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.tokenize_procedure-Tuple{Any, Any, Any}","page":"Home","title":"TextEncodeBase.tokenize_procedure","text":"tokenization_procedure(tokenizer, tokenizaton, stage)\n\nThe procedure of tokenization (splitting + wrap + tokenize).  This is use to restore full behavior for stage that default  unsplittable. Generally don't overload this function.\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.trunc_and_pad-Tuple{Any, Integer, Any}","page":"Home","title":"TextEncodeBase.trunc_and_pad","text":"trunc_and_pad(x, n, pad)\n\ntruncate x to length n, otherwise add pad at the end of x until length equal n.  x can be either nested or single array (but the element type should not be subtype of abstract array).  if n is nothing, the largest length of the nested array will be used.\n\nExample\n\njulia> TextEncodeBase.trunc_and_pad(1:5, 7, -1)\n7-element Vector{Int64}:\n  1\n  2\n  3\n  4\n  5\n -1\n -1\n\njulia> TextEncodeBase.trunc_and_pad([1:5, 2:7], 7, -1)\n2-element Vector{Vector{Int64}}:\n [1, 2, 3, 4, 5, -1, -1]\n [2, 3, 4, 5, 6, 7, -1]\n\njulia> TextEncodeBase.trunc_and_pad([1:5, [2:7, [1:2]]], nothing, -1)\n2-element Vector{Vector}:\n [1, 2, 3, 4, 5, -1]\n Vector[[2, 3, 4, 5, 6, 7], [[1, 2, -1, -1, -1, -1]]]\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.with_head_tail-Tuple{Any, Any, Any}","page":"Home","title":"TextEncodeBase.with_head_tail","text":"with_head_tail(x, head, tail)\n\nReturn [head; x; tail]. Ignored if head or tail is nothing.\n\nExample\n\njulia> TextEncodeBase.with_head_tail(1:5, -1, -2)\n7-element Vector{Int64}:\n -1\n  1\n  2\n  3\n  4\n  5\n -2\n\njulia> TextEncodeBase.with_head_tail([1:5, 2:3], -1, -2)\n2-element Vector{Vector{Int64}}:\n [-1, 1, 2, 3, 4, 5, -2]\n [-1, 2, 3, -2]\n\n\n\n\n\n\n","category":"method"},{"location":"#TextEncodeBase.wrap","page":"Home","title":"TextEncodeBase.wrap","text":"wrap(t::AbstractTokenization, s::TokenStages, x)\n\nMark the tokenization stage of x, which is part of the splitting result of s.  For example, if we are doing simple whitespace tokenization and at the sentence stage,  then x is just single word of s and thus return Word(x) (or Token(x)).  Skip if x is already a TokenStages. (this method only apply to splittable stages)\n\nOverload this method to control the tokenization process.\n\n\n\n\n\n","category":"function"},{"location":"#TextEncodeBase.wrap-Tuple{TextEncodeBase.AbstractTokenization, TextEncodeBase.TokenStages}","page":"Home","title":"TextEncodeBase.wrap","text":"wrap(t::AbstractTokenization, x::TokenStages)\n\nA handler for unsplittable stages (token/word/...).\n\nOverload this method for custom transform.\n\n\n\n\n\n","category":"method"}]
}
